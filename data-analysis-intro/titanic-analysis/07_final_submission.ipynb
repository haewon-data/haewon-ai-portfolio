{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79d8035b",
   "metadata": {},
   "source": [
    "# üõ≥Ô∏è Final Submission\n",
    "\n",
    "This notebook wraps up the Titanic survival prediction project.  \n",
    "After evaluating all candidate models, we select the best-performing one, generate the final `.csv` file for submission,<br> and summarize key takeaways from the project.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Purpose\n",
    "\n",
    "To finalize the project by:\n",
    "- Selecting the most suitable model based on evaluation metrics  \n",
    "- Generating the submission file in the required format  \n",
    "- Reflecting briefly on the overall process\n",
    "\n",
    "## üì¶ Dataset\n",
    "\n",
    "Same processed dataset used in earlier notebooks:  \n",
    "[Titanic - Machine Learning from Disaster](https://www.kaggle.com/c/titanic)  \n",
    "via public repository: [Data Science Dojo GitHub](https://github.com/datasciencedojo/datasets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e35c339",
   "metadata": {},
   "source": [
    "üì¶ 1. Load the Dataset & Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36293f5",
   "metadata": {},
   "source": [
    "We load the same processed dataset and reuse the train/test split  \n",
    "to ensure consistency with the previous evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83f49d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load processed dataset\n",
    "df = pd.read_csv(\"feature_engineered_titanic.csv\")\n",
    "\n",
    "# Target and features\n",
    "y = df['Survived']\n",
    "X_full = df.drop(columns=['Survived', 'Name', 'Ticket', 'PassengerId'])\n",
    "X_safe = X_full.drop(columns=['Cabin', 'Title'])\n",
    "\n",
    "# Shared train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_safe, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1ddc16",
   "metadata": {},
   "source": [
    "ü§ñ 2. Train the Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ebb7ad",
   "metadata": {},
   "source": [
    "Based on the evaluation results,  \n",
    "we select `GradientBoostingClassifier` as the final model due to its consistently strong performance across all metrics, including F1 Score and AUC.\n",
    "\n",
    "We'll now retrain it on the training set and generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99191064",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize and train the final model\n",
    "final_model = GradientBoostingClassifier(random_state=42)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "final_preds = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c9dbfa",
   "metadata": {},
   "source": [
    "üìÑ 3. Generate the Submission File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d58e1b7",
   "metadata": {},
   "source": [
    "To prepare for submission, we generate predictions using the final model.  \n",
    "The output file follows the required Kaggle format with the following columns:\n",
    "\n",
    "- `PassengerId`: ID from the original dataset  \n",
    "- `Survived`: Predicted survival (0 or 1)\n",
    "\n",
    "The file will be saved as `submission.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3d54412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload original dataframe to retrieve PassengerId\n",
    "df_original = pd.read_csv(\"feature_engineered_titanic.csv\")\n",
    "passenger_ids = df_original.loc[X_test.index, 'PassengerId']\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": passenger_ids,\n",
    "    \"Survived\": final_preds\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c99898",
   "metadata": {},
   "source": [
    "### üß† Summary\n",
    "In this notebook, I finalized the Titanic survival prediction project by:\n",
    "\n",
    "- Selecting `GradientBoostingClassifier` as the final model based on F1 score and ROC AUC  \n",
    "- Retraining the model on the training set  \n",
    "- Generating predictions and saving the result as `submission.csv` in Kaggle format\n",
    "\n",
    "This marks the completion of the core workflow.  \n",
    "Future improvements could include hyperparameter tuning, model stacking, or feature expansion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abc0f2d",
   "metadata": {},
   "source": [
    "## üì¶ Overall Summary\n",
    "\n",
    "This notebook concludes a 7-part beginner-friendly Titanic survival prediction project.\n",
    "\n",
    "Throughout the series, I explored:\n",
    "- Data cleaning and visualization (01‚Äì02)\n",
    "- Feature engineering (03‚Äì04)\n",
    "- Model building and evaluation (05‚Äì06)\n",
    "- Final model selection and submission preparation (07)\n",
    "\n",
    "By completing this project, I practiced core data science skills such as:\n",
    "- Exploratory data analysis (EDA)\n",
    "- Feature preprocessing and transformation\n",
    "- Model selection and evaluation using multiple metrics\n",
    "- Real-world prediction workflow aligned with Kaggle submission format\n",
    "\n",
    "This was my first fully documented project on GitHub,  \n",
    "and it helped me build both skills and confidence in the data science workflow.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
